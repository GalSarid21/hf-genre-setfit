{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgVDq57_42aM"
      },
      "source": [
        "#Installations & Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeCcf6d37OFb"
      },
      "source": [
        "Installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQFImylX17i9"
      },
      "outputs": [],
      "source": [
        "!pip install setfit\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPEGtMf87RQt"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gW6ocvkP7Q0z"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers.losses import CosineSimilarityLoss\n",
        "from setfit import SetFitTrainer, SetFitModel\n",
        "from datasets import Dataset\n",
        "\n",
        "import huggingface_hub as hf_hub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import csv\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAHTMPvW5Pfy"
      },
      "source": [
        "#Set Consts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Apw5co7I5RZz"
      },
      "outputs": [],
      "source": [
        "TRAIN_FILE_PATH = '/content/sample_data/train-00000-of-00001-b943ea66e0040b18.parquet'\n",
        "TEST_FILE_PATH = '/content/sample_data/test-00000-of-00001-35e9a9274361daed.parquet'\n",
        "OUTPUT_SUBMISSION_PATH = '/content/sample_data/submission.csv'\n",
        "OUTPUT_MODEL_NAME = 'GalSarid/setfit-movie-genre-sentence-t5-xl'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZs7VB4L5D-P"
      },
      "source": [
        "#Explore the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwNBum9H5IbG"
      },
      "outputs": [],
      "source": [
        "base_df = pd.read_parquet(TRAIN_FILE_PATH, engine='pyarrow')\n",
        "base_df.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nGRUaGf8UU8"
      },
      "source": [
        "Check label distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nF7V6A3b699F"
      },
      "outputs": [],
      "source": [
        "def get_unique_labels(df: pd.DataFrame, group_name: str, print_labels_dist: bool) -> list:\n",
        "  if print_labels_dist:\n",
        "    print(f\"num of rows: {len(df)}\")\n",
        "  label_rows = df.groupby(group_name)\n",
        "  if print_labels_dist:\n",
        "    print(f\"num of labels: {len(label_rows)}\")\n",
        "    print(label_rows.size())\n",
        "  labels = [lr[0] for lr in label_rows]\n",
        "  return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOXL54E6Lqj1"
      },
      "outputs": [],
      "source": [
        "labels  = get_unique_labels(base_df, 'genre', print_labels_dist=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tYGdWPHG2J4"
      },
      "source": [
        "#Train model and creat submission file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkarWs0J8va-"
      },
      "source": [
        "Clean synopsis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7m7k88yPZWcN"
      },
      "outputs": [],
      "source": [
        "def remove_see_full_synopsis(raw_synopsis: str) -> str:\n",
        "  clean_synopsis = re.sub(r\"[^\\x00-\\x7F]+\",\"\", raw_synopsis)\n",
        "  clean_synopsis = re.sub(\"...                See full synopsis\", \"\", clean_synopsis)\n",
        "  return clean_synopsis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5axbFqlw83eX"
      },
      "outputs": [],
      "source": [
        "test_id = 22430\n",
        "test_row = base_df[base_df.id == test_id].iloc[0]\n",
        "test_str = test_row['synopsis']\n",
        "print(f'Orig:\\n{test_str}')\n",
        "print(f'Without see full synopsis:\\n{remove_see_full_synopsis(test_str)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvw06VaV9ox1"
      },
      "source": [
        "Create genre-id and id-genre dicts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIcUkxJ_9xve"
      },
      "outputs": [],
      "source": [
        "genre_id_mappings = {}\n",
        "id_genre_mappings = {}\n",
        "\n",
        "for l,i in zip(labels, range(len(labels))):\n",
        "  genre_id_mappings.update({l:i})\n",
        "  id_genre_mappings.update({i:l})\n",
        "\n",
        "print(genre_id_mappings)\n",
        "print(id_genre_mappings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnEWtH-4CphI"
      },
      "source": [
        "Train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtI7wzu9pq-D"
      },
      "outputs": [],
      "source": [
        "base_df[\"genre_id\"] = base_df[\"genre\"].map(genre_id_mappings)\n",
        "print(base_df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgKak8Z3CpNu"
      },
      "outputs": [],
      "source": [
        "hp_train_df = base_df.sample(frac=0.02, random_state=42)\n",
        "hp_test_df = base_df.drop(hp_train_df.index)\n",
        "hp_test_df = hp_test_df.sample(frac=0.01, random_state=42)\n",
        "\n",
        "print(get_unique_labels(hp_train_df, 'genre', print_labels_dist=True))\n",
        "print(get_unique_labels(hp_test_df, 'genre', print_labels_dist=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s89PlWLqOX0Z"
      },
      "outputs": [],
      "source": [
        "train_synopsis_df = base_df.sample(frac=0.9, random_state=42)\n",
        "test_synopsis_df = base_df.drop(train_synopsis_df.index)\n",
        "print(f'Orig trian length: {len(train_synopsis_df)}')\n",
        "\n",
        "synopsis_seen = []\n",
        "valid_ids = []\n",
        "\n",
        "for row in train_synopsis_df.iterrows():\n",
        "  if row[-1]['synopsis'] not in synopsis_seen:\n",
        "    valid_ids.append(row[-1]['id'])\n",
        "    synopsis_seen.append(row[-1]['synopsis'])\n",
        "\n",
        "train_synopsis_df = train_synopsis_df.query('id in @valid_ids')\n",
        "\n",
        "print(f'After duplication cleaning: {len(train_synopsis_df)}')\n",
        "print(f'Test length without cleaning: {len(test_synopsis_df)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check train-test label distribution"
      ],
      "metadata": {
        "id": "3PrM-YM6b1XL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCFVk_W9MkoN"
      },
      "outputs": [],
      "source": [
        "train_labels = get_unique_labels(train_synopsis_df, 'genre', True)\n",
        "print()\n",
        "test_labels = get_unique_labels(test_synopsis_df, 'genre', True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-eIz-YyMSos"
      },
      "source": [
        "Create text-labels dicts for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozupWfwFaLza"
      },
      "outputs": [],
      "source": [
        "def get_setfit_data_dict(df: pd.DataFrame) -> dict:\n",
        "    setfit_data_dict = {\n",
        "        'text': list(map(lambda row: remove_see_full_synopsis(f\"{row[-1]['synopsis']}: {row[-1]['synopsis']}\"),\n",
        "                     df.iterrows())),\n",
        "        'label': list(df['genre_id'])\n",
        "    }\n",
        "\n",
        "    return setfit_data_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wiPCZDUob7hr"
      },
      "outputs": [],
      "source": [
        "hp_search_data_dict_train = get_setfit_data_dict(hp_train_df)\n",
        "hp_search_data_dict_test = get_setfit_data_dict(hp_test_df)\n",
        "\n",
        "train_data_dict = get_setfit_data_dict(train_synopsis_df)\n",
        "test_data_dict = get_setfit_data_dict(test_synopsis_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdUPxaMxOdtD"
      },
      "source": [
        "Set model and model params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "M_CwxiBjKLQ_"
      },
      "outputs": [],
      "source": [
        "num_classes = len(labels)\n",
        "model_name = 'sentence-transformers/sentence-t5-xl'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSGddU4bHsVi"
      },
      "source": [
        "Load pretrained t5-xl model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f8Ayq22RcM9"
      },
      "outputs": [],
      "source": [
        "synopsis_data_model = SetFitModel.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3zlr16PgcnE"
      },
      "source": [
        "Init trainer with HP search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wq45XlFHf_2w"
      },
      "outputs": [],
      "source": [
        "def make_model(params=None):\n",
        "    return SetFitModel.from_pretrained(model_name)\n",
        "\n",
        "hp_search_trainer = SetFitTrainer(\n",
        "    model_init=make_model,\n",
        "    train_dataset=Dataset.from_dict(hp_search_data_dict_train),\n",
        "    eval_dataset=Dataset.from_dict(hp_search_data_dict_test),\n",
        "    loss_class=CosineSimilarityLoss,\n",
        "    column_mapping={\"text\": \"text\", \"label\": \"label\"},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0QK-94s5gs_"
      },
      "outputs": [],
      "source": [
        "def hyperparameter_search_function(trial):\n",
        "    return {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=False),\n",
        "        \"batch_size\": trial.suggest_categorical(\"batch_size\", [4, 8, 16]),\n",
        "        \"num_iterations\": trial.suggest_categorical(\"num_iterations\", [1, 2]),\n",
        "        \"num_epochs\": trial.suggest_categorical(\"num_epochs\", [1, 2, 4])\n",
        "    }\n",
        "\n",
        "best = hp_search_trainer.hyperparameter_search(hyperparameter_search_function, n_trials=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOTCRbRqrsn3"
      },
      "outputs": [],
      "source": [
        "best"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load pretrained t5-xl model"
      ],
      "metadata": {
        "id": "OfWQL-LWcuXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t5_pretrained = SetFitModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "ex1vMxoMclKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUlfXX0aaLzn"
      },
      "source": [
        "Init setfit trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N74FBgom_Nst"
      },
      "outputs": [],
      "source": [
        "t5_data_trainer = SetFitTrainer(\n",
        "    model = t5_pretrained,\n",
        "    train_dataset = Dataset.from_dict(train_data_dict),\n",
        "    eval_dataset = Dataset.from_dict(test_data_dict),\n",
        "    loss_class = CosineSimilarityLoss,\n",
        "    column_mapping = {\"text\": \"text\", \"label\": \"label\"},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c91hvhliaLzo"
      },
      "source": [
        "Train model with HP found"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDGEZ11O8WSf"
      },
      "outputs": [],
      "source": [
        "t5_data_trainer.apply_hyperparameters(best.hyperparameters, final_model=True)\n",
        "torch.cuda.empty_cache()\n",
        "t5_data_trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate model"
      ],
      "metadata": {
        "id": "9hF7qSgZndCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t5_data_trainer.evaluate()"
      ],
      "metadata": {
        "id": "ocbW3maUncjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLY79njjaL0t"
      },
      "source": [
        "Connect to HF hub and save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiWc4nnx0Wd9"
      },
      "outputs": [],
      "source": [
        "hf_hub.notebook_login()\n",
        "t5_data_trainer.push_to_hub(OUTPUT_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the test file and make predictions"
      ],
      "metadata": {
        "id": "N1IkFnyufKin"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zT1NzNiJHVO"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_parquet(TEST_FILE_PATH, engine='pyarrow')\n",
        "test_synopsis = test_df['synopsis']\n",
        "test_synopsis_clean = list(map(lambda x: remove_see_full_synopsis(x), test_synopsis.values))\n",
        "\n",
        "preds = t5_data_trainer.model.predict(test_synopsis_clean)\n",
        "preds"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create submission csv"
      ],
      "metadata": {
        "id": "wapo-gryfViO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8XVPN1U98XU"
      },
      "outputs": [],
      "source": [
        "def create_submission_dataset(df: pd.DataFrame,\n",
        "                              preds: list,\n",
        "                              mappings: dict,\n",
        "                              path: str) -> bool:\n",
        "    if len(df) != len(preds):\n",
        "      return False\n",
        "\n",
        "    submission_file_data = []\n",
        "    headers = ['id', 'genre']\n",
        "    submission_file_data.append(headers)\n",
        "\n",
        "    for i in range(len(preds)):\n",
        "      submission_file_data.append(\n",
        "          [df.iloc[i]['id'], mappings.get(int(preds[i]))]\n",
        "      )\n",
        "\n",
        "    with open(path, 'w', encoding='UTF8', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerows(submission_file_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-yrW8kOAa-3"
      },
      "outputs": [],
      "source": [
        "create_submission_dataset(test_df, preds, id_genre_mappings, OUTPUT_SUBMISSION_PATH)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}